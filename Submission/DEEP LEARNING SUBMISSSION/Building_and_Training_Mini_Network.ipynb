{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JzycIPSy2AKH"
      },
      "source": [
        "## Download the Repository\n",
        "\n",
        "[Repository Link](https://github.com/pijush2022/Lane_detection)\n",
        "\n",
        "- This is our team's repository. This repository contains all the necessary code that we worked on and it also contains the dataset that we annotated.\n",
        "\n",
        "- You do not need to do anything like uploading and adjusting the paths. Just run the cells sequentially.\n",
        "\n",
        "- All the necessary commands are written in this notebook itself"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "dyznWPpKmNIs",
        "outputId": "27d666fb-db00-40d8-e985-95e70d723f94"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'road-detection' already exists and is not an empty directory.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/pijush2022/Lane_detection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AVXcandz2wFA"
      },
      "source": [
        "## Install the Requirements\n",
        "\n",
        "- Install all the python dependencies\n",
        "- After Installing dependencies, Restart the runtime. If you do not restart the runtime, the python will throw \"module not found error\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "298SpxZcDf1R",
        "outputId": "41b88ed1-e10d-49e9-e57e-5760394d5a91"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: certifi==2023.7.22 in /usr/local/lib/python3.10/dist-packages (from -r road-detection/TwinLiteNet/requirements.txt (line 1)) (2023.7.22)\n",
            "Requirement already satisfied: charset-normalizer==3.3.2 in /usr/local/lib/python3.10/dist-packages (from -r road-detection/TwinLiteNet/requirements.txt (line 2)) (3.3.2)\n",
            "Requirement already satisfied: colorama==0.4.6 in /usr/local/lib/python3.10/dist-packages (from -r road-detection/TwinLiteNet/requirements.txt (line 3)) (0.4.6)\n",
            "Requirement already satisfied: contourpy==1.2.0 in /usr/local/lib/python3.10/dist-packages (from -r road-detection/TwinLiteNet/requirements.txt (line 4)) (1.2.0)\n",
            "Requirement already satisfied: cycler==0.12.1 in /usr/local/lib/python3.10/dist-packages (from -r road-detection/TwinLiteNet/requirements.txt (line 5)) (0.12.1)\n",
            "Requirement already satisfied: dnspython==2.4.2 in /usr/local/lib/python3.10/dist-packages (from -r road-detection/TwinLiteNet/requirements.txt (line 6)) (2.4.2)\n",
            "Requirement already satisfied: elephant==0.12.0 in /usr/local/lib/python3.10/dist-packages (from -r road-detection/TwinLiteNet/requirements.txt (line 7)) (0.12.0)\n",
            "Requirement already satisfied: filelock==3.13.1 in /usr/local/lib/python3.10/dist-packages (from -r road-detection/TwinLiteNet/requirements.txt (line 8)) (3.13.1)\n",
            "Requirement already satisfied: fonttools==4.44.0 in /usr/local/lib/python3.10/dist-packages (from -r road-detection/TwinLiteNet/requirements.txt (line 9)) (4.44.0)\n",
            "Requirement already satisfied: fsspec==2023.10.0 in /usr/local/lib/python3.10/dist-packages (from -r road-detection/TwinLiteNet/requirements.txt (line 10)) (2023.10.0)\n",
            "Requirement already satisfied: idna==3.4 in /usr/local/lib/python3.10/dist-packages (from -r road-detection/TwinLiteNet/requirements.txt (line 11)) (3.4)\n",
            "Requirement already satisfied: Jinja2==3.1.2 in /usr/local/lib/python3.10/dist-packages (from -r road-detection/TwinLiteNet/requirements.txt (line 12)) (3.1.2)\n",
            "Requirement already satisfied: joblib==1.2.0 in /usr/local/lib/python3.10/dist-packages (from -r road-detection/TwinLiteNet/requirements.txt (line 13)) (1.2.0)\n",
            "Requirement already satisfied: kiwisolver==1.4.5 in /usr/local/lib/python3.10/dist-packages (from -r road-detection/TwinLiteNet/requirements.txt (line 14)) (1.4.5)\n",
            "Requirement already satisfied: MarkupSafe==2.1.3 in /usr/local/lib/python3.10/dist-packages (from -r road-detection/TwinLiteNet/requirements.txt (line 15)) (2.1.3)\n",
            "Requirement already satisfied: matplotlib==3.7.1 in /usr/local/lib/python3.10/dist-packages (from -r road-detection/TwinLiteNet/requirements.txt (line 16)) (3.7.1)\n",
            "Requirement already satisfied: mpmath==1.3.0 in /usr/local/lib/python3.10/dist-packages (from -r road-detection/TwinLiteNet/requirements.txt (line 17)) (1.3.0)\n",
            "Requirement already satisfied: neo==0.12.0 in /usr/local/lib/python3.10/dist-packages (from -r road-detection/TwinLiteNet/requirements.txt (line 18)) (0.12.0)\n",
            "Requirement already satisfied: networkx==3.2.1 in /usr/local/lib/python3.10/dist-packages (from -r road-detection/TwinLiteNet/requirements.txt (line 19)) (3.2.1)\n",
            "Requirement already satisfied: numpy==1.24.3 in /usr/local/lib/python3.10/dist-packages (from -r road-detection/TwinLiteNet/requirements.txt (line 20)) (1.24.3)\n",
            "Requirement already satisfied: opencv-python==4.7.0.72 in /usr/local/lib/python3.10/dist-packages (from -r road-detection/TwinLiteNet/requirements.txt (line 21)) (4.7.0.72)\n",
            "Requirement already satisfied: packaging==23.2 in /usr/local/lib/python3.10/dist-packages (from -r road-detection/TwinLiteNet/requirements.txt (line 22)) (23.2)\n",
            "Requirement already satisfied: Pillow==9.5.0 in /usr/local/lib/python3.10/dist-packages (from -r road-detection/TwinLiteNet/requirements.txt (line 23)) (9.5.0)\n",
            "Requirement already satisfied: pyparsing==3.1.1 in /usr/local/lib/python3.10/dist-packages (from -r road-detection/TwinLiteNet/requirements.txt (line 24)) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil==2.8.2 in /usr/local/lib/python3.10/dist-packages (from -r road-detection/TwinLiteNet/requirements.txt (line 25)) (2.8.2)\n",
            "Requirement already satisfied: python-etcd==0.4.5 in /usr/local/lib/python3.10/dist-packages (from -r road-detection/TwinLiteNet/requirements.txt (line 26)) (0.4.5)\n",
            "Requirement already satisfied: PyYAML==6.0.1 in /usr/local/lib/python3.10/dist-packages (from -r road-detection/TwinLiteNet/requirements.txt (line 27)) (6.0.1)\n",
            "Requirement already satisfied: quantities==0.14.1 in /usr/local/lib/python3.10/dist-packages (from -r road-detection/TwinLiteNet/requirements.txt (line 28)) (0.14.1)\n",
            "Requirement already satisfied: requests==2.31.0 in /usr/local/lib/python3.10/dist-packages (from -r road-detection/TwinLiteNet/requirements.txt (line 29)) (2.31.0)\n",
            "Requirement already satisfied: scikit-learn==1.3.2 in /usr/local/lib/python3.10/dist-packages (from -r road-detection/TwinLiteNet/requirements.txt (line 30)) (1.3.2)\n",
            "Requirement already satisfied: scipy==1.10.1 in /usr/local/lib/python3.10/dist-packages (from -r road-detection/TwinLiteNet/requirements.txt (line 31)) (1.10.1)\n",
            "Requirement already satisfied: six==1.16.0 in /usr/local/lib/python3.10/dist-packages (from -r road-detection/TwinLiteNet/requirements.txt (line 32)) (1.16.0)\n",
            "Requirement already satisfied: sympy==1.12 in /usr/local/lib/python3.10/dist-packages (from -r road-detection/TwinLiteNet/requirements.txt (line 33)) (1.12)\n",
            "Requirement already satisfied: threadpoolctl==3.2.0 in /usr/local/lib/python3.10/dist-packages (from -r road-detection/TwinLiteNet/requirements.txt (line 34)) (3.2.0)\n",
            "Requirement already satisfied: torch==2.1.0 in /usr/local/lib/python3.10/dist-packages (from -r road-detection/TwinLiteNet/requirements.txt (line 35)) (2.1.0)\n",
            "Requirement already satisfied: torchdata==0.7.0 in /usr/local/lib/python3.10/dist-packages (from -r road-detection/TwinLiteNet/requirements.txt (line 36)) (0.7.0)\n",
            "Requirement already satisfied: torchelastic==0.2.2 in /usr/local/lib/python3.10/dist-packages (from -r road-detection/TwinLiteNet/requirements.txt (line 37)) (0.2.2)\n",
            "Requirement already satisfied: torchtext==0.16.0 in /usr/local/lib/python3.10/dist-packages (from -r road-detection/TwinLiteNet/requirements.txt (line 38)) (0.16.0)\n",
            "Requirement already satisfied: torchvision==0.16.0 in /usr/local/lib/python3.10/dist-packages (from -r road-detection/TwinLiteNet/requirements.txt (line 39)) (0.16.0)\n",
            "Requirement already satisfied: tqdm==4.66.1 in /usr/local/lib/python3.10/dist-packages (from -r road-detection/TwinLiteNet/requirements.txt (line 40)) (4.66.1)\n",
            "Requirement already satisfied: typing_extensions==4.8.0 in /usr/local/lib/python3.10/dist-packages (from -r road-detection/TwinLiteNet/requirements.txt (line 41)) (4.8.0)\n",
            "Requirement already satisfied: urllib3==2.0.7 in /usr/local/lib/python3.10/dist-packages (from -r road-detection/TwinLiteNet/requirements.txt (line 42)) (2.0.7)\n",
            "Requirement already satisfied: webcolors==1.13 in /usr/local/lib/python3.10/dist-packages (from -r road-detection/TwinLiteNet/requirements.txt (line 43)) (1.13)\n",
            "Requirement already satisfied: yacs==0.1.8 in /usr/local/lib/python3.10/dist-packages (from -r road-detection/TwinLiteNet/requirements.txt (line 44)) (0.1.8)\n",
            "Requirement already satisfied: zipp==3.15.0 in /usr/local/lib/python3.10/dist-packages (from -r road-detection/TwinLiteNet/requirements.txt (line 45)) (3.15.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->-r road-detection/TwinLiteNet/requirements.txt (line 35)) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->-r road-detection/TwinLiteNet/requirements.txt (line 35)) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->-r road-detection/TwinLiteNet/requirements.txt (line 35)) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->-r road-detection/TwinLiteNet/requirements.txt (line 35)) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->-r road-detection/TwinLiteNet/requirements.txt (line 35)) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->-r road-detection/TwinLiteNet/requirements.txt (line 35)) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->-r road-detection/TwinLiteNet/requirements.txt (line 35)) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->-r road-detection/TwinLiteNet/requirements.txt (line 35)) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->-r road-detection/TwinLiteNet/requirements.txt (line 35)) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.18.1 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->-r road-detection/TwinLiteNet/requirements.txt (line 35)) (2.18.1)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->-r road-detection/TwinLiteNet/requirements.txt (line 35)) (12.1.105)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->-r road-detection/TwinLiteNet/requirements.txt (line 35)) (2.1.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.1.0->-r road-detection/TwinLiteNet/requirements.txt (line 35)) (12.4.127)\n"
          ]
        }
      ],
      "source": [
        "!pip install -r road-detection/TwinLiteNet/requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WtYxavR2503Q"
      },
      "source": [
        "## Copy Dataset from Repository\n",
        "\n",
        "- Our repository contains dataset.zip in datasets folder in the repository. copy that zip file to root"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "ihjXltFR1OQI"
      },
      "outputs": [],
      "source": [
        "!cp road-detection/datasets/dataset.zip ./"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ferlFJ_76GBA"
      },
      "source": [
        "## Unzip the file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "w7AUZJZ0f491",
        "outputId": "5d714cc6-3d9b-450e-8c54-22dc8feb706c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  dataset.zip\n",
            "replace dataset/test/images/road_image_160.png? [y]es, [n]o, [A]ll, [N]one, [r]ename: N\n"
          ]
        }
      ],
      "source": [
        "!unzip dataset.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bpUdANiK6K-i"
      },
      "source": [
        "## Import the all the required libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "hVDJcpeP5d1J"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import cv2\n",
        "import torch.utils.data\n",
        "import torchvision.transforms as transforms\n",
        "import numpy as np\n",
        "import os\n",
        "import random\n",
        "import math\n",
        "from matplotlib import pyplot as plt\n",
        "import torch.nn as nn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MXX5-aH58B4c"
      },
      "source": [
        "## Image transformation functions\n",
        "\n",
        "- By paper author"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "ywi8_wbg5jZQ"
      },
      "outputs": [],
      "source": [
        "def augment_hsv(img, hgain=0.015, sgain=0.7, vgain=0.4):\n",
        "    \"\"\"change color hue, saturation, value\"\"\"\n",
        "    r = np.random.uniform(-1, 1, 3) * [hgain, sgain, vgain] + 1  # random gains\n",
        "    hue, sat, val = cv2.split(cv2.cvtColor(img, cv2.COLOR_BGR2HSV))\n",
        "    dtype = img.dtype  # uint8\n",
        "\n",
        "    x = np.arange(0, 256, dtype=np.int16)\n",
        "    lut_hue = ((x * r[0]) % 180).astype(dtype)\n",
        "    lut_sat = np.clip(x * r[1], 0, 255).astype(dtype)\n",
        "    lut_val = np.clip(x * r[2], 0, 255).astype(dtype)\n",
        "\n",
        "    img_hsv = cv2.merge((cv2.LUT(hue, lut_hue), cv2.LUT(sat, lut_sat), cv2.LUT(val, lut_val))).astype(dtype)\n",
        "    cv2.cvtColor(img_hsv, cv2.COLOR_HSV2BGR, dst=img)  # no return needed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "NMEu5Ey35mWQ"
      },
      "outputs": [],
      "source": [
        "def random_perspective(combination,  degrees=10, translate=.1, scale=.1, shear=10, perspective=0.0, border=(0, 0)):\n",
        "    \"\"\"combination of img transform\"\"\"\n",
        "    # torchvision.transforms.RandomAffine(degrees=(-10, 10), translate=(.1, .1), scale=(.9, 1.1), shear=(-10, 10))\n",
        "    # targets = [cls, xyxy]\n",
        "    img, gray, line = combination\n",
        "    height = img.shape[0] + border[0] * 2  # shape(h,w,c)\n",
        "    width = img.shape[1] + border[1] * 2\n",
        "\n",
        "    # Center\n",
        "    C = np.eye(3)\n",
        "    C[0, 2] = -img.shape[1] / 2  # x translation (pixels)\n",
        "    C[1, 2] = -img.shape[0] / 2  # y translation (pixels)\n",
        "\n",
        "    # Perspective\n",
        "    P = np.eye(3)\n",
        "    P[2, 0] = random.uniform(-perspective, perspective)  # x perspective (about y)\n",
        "    P[2, 1] = random.uniform(-perspective, perspective)  # y perspective (about x)\n",
        "\n",
        "    # Rotation and Scale\n",
        "    R = np.eye(3)\n",
        "    a = random.uniform(-degrees, degrees)\n",
        "    # a += random.choice([-180, -90, 0, 90])  # add 90deg rotations to small rotations\n",
        "    s = random.uniform(1 - scale, 1 + scale)\n",
        "    # s = 2 ** random.uniform(-scale, scale)\n",
        "    R[:2] = cv2.getRotationMatrix2D(angle=a, center=(0, 0), scale=s)\n",
        "\n",
        "    # Shear\n",
        "    S = np.eye(3)\n",
        "    S[0, 1] = math.tan(random.uniform(-shear, shear) * math.pi / 180)  # x shear (deg)\n",
        "    S[1, 0] = math.tan(random.uniform(-shear, shear) * math.pi / 180)  # y shear (deg)\n",
        "\n",
        "    # Translation\n",
        "    T = np.eye(3)\n",
        "    T[0, 2] = random.uniform(0.5 - translate, 0.5 + translate) * width  # x translation (pixels)\n",
        "    T[1, 2] = random.uniform(0.5 - translate, 0.5 + translate) * height  # y translation (pixels)\n",
        "\n",
        "    # Combined rotation matrix\n",
        "    M = T @ S @ R @ P @ C  # order of operations (right to left) is IMPORTANT\n",
        "    if (border[0] != 0) or (border[1] != 0) or (M != np.eye(3)).any():  # image changed\n",
        "        if perspective:\n",
        "            img = cv2.warpPerspective(img, M, dsize=(width, height), borderValue=(114, 114, 114))\n",
        "            gray = cv2.warpPerspective(gray, M, dsize=(width, height), borderValue=0)\n",
        "            line = cv2.warpPerspective(line, M, dsize=(width, height), borderValue=0)\n",
        "        else:  # affine\n",
        "            img = cv2.warpAffine(img, M[:2], dsize=(width, height), borderValue=(114, 114, 114))\n",
        "            gray = cv2.warpAffine(gray, M[:2], dsize=(width, height), borderValue=0)\n",
        "            line = cv2.warpAffine(line, M[:2], dsize=(width, height), borderValue=0)\n",
        "\n",
        "\n",
        "\n",
        "    combination = (img, gray, line)\n",
        "    return combination"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "8XX_6sn33Qpc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "5593c775-706b-42b6-c2f6-a997b4b43ff8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘custom-dataset’: File exists\n",
            "mkdir: cannot create directory ‘custom-dataset/test’: File exists\n",
            "mkdir: cannot create directory ‘custom-dataset/train’: File exists\n",
            "mkdir: cannot create directory ‘custom-dataset/validation’: File exists\n"
          ]
        }
      ],
      "source": [
        "!mkdir custom-dataset\n",
        "!mkdir custom-dataset/test\n",
        "!mkdir custom-dataset/train\n",
        "!mkdir custom-dataset/validation\n",
        "\n",
        "!mkdir -p custom-dataset/train/images\n",
        "!mkdir -p custom-dataset/train/lane\n",
        "!mkdir -p custom-dataset/train/segments\n",
        "!mkdir -p custom-dataset/test/images\n",
        "!mkdir -p custom-dataset/test/lane\n",
        "!mkdir -p custom-dataset/test/segments\n",
        "!mkdir -p custom-dataset/validation/images\n",
        "!mkdir -p custom-dataset/validation/lane\n",
        "!mkdir -p custom-dataset/validation/segments\n",
        "\n",
        "# Copy only two images from each category in train\n",
        "!cp dataset/train/images/road_image_0.png custom-dataset/train/images/\n",
        "!cp dataset/train/lane/road_image_0.png custom-dataset/train/lane/\n",
        "!cp dataset/train/segments/road_image_0.png custom-dataset/train/segments/\n",
        "\n",
        "# Copy only two images from each category in train\n",
        "!cp dataset/train/images/road_image_1.png custom-dataset/train/images/\n",
        "!cp dataset/train/lane/road_image_1.png custom-dataset/train/lane/\n",
        "!cp dataset/train/segments/road_image_1.png custom-dataset/train/segments/\n",
        "\n",
        "# Copy only two images from each category in test\n",
        "!cp dataset/test/images/* custom-dataset/test/images/\n",
        "!cp dataset/test/lane/* custom-dataset/test/lane/\n",
        "!cp dataset/test/segments/* custom-dataset/test/segments/\n",
        "\n",
        "\n",
        "# Copy only two images from each category in validation\n",
        "!cp dataset/validation/images/* custom-dataset/validation/images/\n",
        "!cp dataset/validation/lane/* custom-dataset/validation/lane/\n",
        "!cp dataset/validation/segments/* custom-dataset/validation/segments/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mFv9HU486TLr"
      },
      "source": [
        "## Custom Dataset Class\n",
        "\n",
        "- This custom dataset class is based on the dataset class written by the author but with slight modifications like path. we have adjusted the path according to the google colab."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "_LoqglKDR2Sw"
      },
      "outputs": [],
      "source": [
        "class MyDataset(torch.utils.data.Dataset):\n",
        "    '''\n",
        "    Class to load the dataset\n",
        "    '''\n",
        "    def __init__(self, transform=None, valid=False, test=False):\n",
        "        '''\n",
        "        :param imList: image list (Note that these lists have been processed and pickled using the loadData.py)\n",
        "        :param labelList: label list (Note that these lists have been processed and pickled using the loadData.py)\n",
        "        :param transform: Type of transformation. SEe Transforms.py for supported transformations\n",
        "        '''\n",
        "\n",
        "        self.transform = transform\n",
        "        self.Tensor = transforms.ToTensor()\n",
        "        self.valid=valid\n",
        "        if valid:\n",
        "            self.root='custom-dataset/validation/images'\n",
        "            self.names=os.listdir(self.root)\n",
        "        elif test:\n",
        "            self.root='custom-dataset/test/images'\n",
        "            self.names=os.listdir(self.root)\n",
        "        else:\n",
        "            self.root='custom-dataset/train/images/'\n",
        "            self.names=os.listdir(self.root)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.names)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        '''\n",
        "\n",
        "        :param idx: Index of the image file\n",
        "        :return: returns the image and corresponding label file.\n",
        "        '''\n",
        "        W_=640\n",
        "        H_=360\n",
        "        image_name=os.path.join(self.root,self.names[idx])\n",
        "\n",
        "        image = cv2.imread(image_name)\n",
        "        original_image = cv2.imread(image_name)\n",
        "        label1 = cv2.imread(image_name.replace(\"images\",\"segments\").replace(\"jpg\",\"png\"), 0)\n",
        "        label2 = cv2.imread(image_name.replace(\"images\",\"lane\").replace(\"jpg\",\"png\"), 0)\n",
        "        if not self.valid:\n",
        "            if random.random()<0.5:\n",
        "                combination = (image, label1, label2)\n",
        "                (image, label1, label2)= random_perspective(\n",
        "                    combination=combination,\n",
        "                    degrees=10,\n",
        "                    translate=0.1,\n",
        "                    scale=0.25,\n",
        "                    shear=0.0\n",
        "                )\n",
        "            if random.random()<0.5:\n",
        "                augment_hsv(image)\n",
        "            if random.random() < 0.5:\n",
        "                image = np.fliplr(image)\n",
        "                label1 = np.fliplr(label1)\n",
        "                label2 = np.fliplr(label2)\n",
        "\n",
        "        label1 = cv2.resize(label1, (W_, H_))\n",
        "        label2 = cv2.resize(label2, (W_, H_))\n",
        "        image = cv2.resize(image, (W_, H_))\n",
        "\n",
        "        _,seg_b1 = cv2.threshold(label1,1,255,cv2.THRESH_BINARY_INV)\n",
        "        _,seg_b2 = cv2.threshold(label2,1,255,cv2.THRESH_BINARY_INV)\n",
        "        _,seg1 = cv2.threshold(label1,1,255,cv2.THRESH_BINARY)\n",
        "        _,seg2 = cv2.threshold(label2,1,255,cv2.THRESH_BINARY)\n",
        "\n",
        "        seg1 = self.Tensor(seg1)\n",
        "        seg2 = self.Tensor(seg2)\n",
        "        seg_b1 = self.Tensor(seg_b1)\n",
        "        seg_b2 = self.Tensor(seg_b2)\n",
        "        seg_da = torch.stack((seg_b1[0], seg1[0]),0)\n",
        "        seg_ll = torch.stack((seg_b2[0], seg2[0]),0)\n",
        "        image = image[:, :, ::-1].transpose(2, 0, 1)\n",
        "        image = np.ascontiguousarray(image)\n",
        "\n",
        "        return original_image, image_name,torch.from_numpy(image),(seg_da,seg_ll)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b6Ly9Ek16kg-"
      },
      "source": [
        "## Intialize a dataloader\n",
        "\n",
        "- Intialize a dataloader with batch size 8\n",
        "\n",
        "- Intialize train, test, validation datasets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "qIK3UcD3STAG"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "train_dataloader = DataLoader(MyDataset(), batch_size = 2, shuffle = True)\n",
        "test_dataloader = DataLoader(MyDataset(test=True), batch_size = 8, shuffle = True)\n",
        "val_dataloader = DataLoader(MyDataset(valid=True), batch_size = 8, shuffle = True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4iZyomcfP7hG"
      },
      "source": [
        "## Take only two samples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "cJ_g-ICbZUR1"
      },
      "outputs": [],
      "source": [
        "_, _, input, target = next(iter(train_dataloader))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qgPKH1aZQB3_"
      },
      "source": [
        "## Copy necessary files from repository"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "T5QDw0IqZgeR"
      },
      "outputs": [],
      "source": [
        "# Copy pretrained model from repository to root\n",
        "!cp road-detection/TwinLiteNet/pretrained/best.pth ./\n",
        "\n",
        "# Copy pytorch Neural Net from repo to root\n",
        "!cp road-detection/TwinLiteNet/model/TwinLite.py ./\n",
        "\n",
        "# Copy Loss function pytorch code from repo to root\n",
        "!cp road-detection/TwinLiteNet/loss.py ./\n",
        "\n",
        "# Copy all reqired constants from repo to root\n",
        "!cp road-detection/TwinLiteNet/const.py ./\n",
        "\n",
        "# Copy all val.py from repo to root\n",
        "!cp road-detection/TwinLiteNet/val.py ./"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LjtBYvEuQGXF"
      },
      "source": [
        "## Mini Version of Original Network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "3U3eUnw0ZqhX"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class MiniNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MiniNet, self).__init__()\n",
        "\n",
        "        # Input Convolution\n",
        "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=2, padding=1)\n",
        "        self.bn1 = nn.BatchNorm2d(16)\n",
        "        self.relu1 = nn.ReLU()\n",
        "\n",
        "        # Downsampling\n",
        "        self.pool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "\n",
        "        # Intermediate Convolutions\n",
        "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1)\n",
        "        self.bn2 = nn.BatchNorm2d(32)\n",
        "        self.relu2 = nn.ReLU()\n",
        "\n",
        "        self.conv3 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
        "        self.bn3 = nn.BatchNorm2d(64)\n",
        "        self.relu3 = nn.ReLU()\n",
        "\n",
        "        # Upsampling\n",
        "        self.upconv1 = nn.ConvTranspose2d(64, 32, kernel_size=4, stride=2, padding=1)\n",
        "        self.bn4 = nn.BatchNorm2d(32)\n",
        "        self.relu4 = nn.ReLU()\n",
        "\n",
        "        self.upconv2 = nn.ConvTranspose2d(32, 16, kernel_size=4, stride=2, padding=1)\n",
        "        self.bn5 = nn.BatchNorm2d(16)\n",
        "        self.relu5 = nn.ReLU()\n",
        "\n",
        "        # Classifiers\n",
        "        self.classifier1 = nn.Conv2d(16, 2, kernel_size=1)\n",
        "        self.classifier2 = nn.Conv2d(16, 2, kernel_size=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Input Convolution\n",
        "        x = self.relu1(self.bn1(self.conv1(x)))\n",
        "\n",
        "        # Downsampling\n",
        "        x = self.pool(x)\n",
        "\n",
        "        # Intermediate Convolutions\n",
        "        x = self.relu2(self.bn2(self.conv2(x)))\n",
        "        x = self.relu3(self.bn3(self.conv3(x)))\n",
        "\n",
        "        # Upsampling\n",
        "        x = self.relu4(self.bn4(self.upconv1(x)))\n",
        "        x = self.relu5(self.bn5(self.upconv2(x)))\n",
        "\n",
        "        # Classifiers\n",
        "        classifier1 = self.classifier1(x)\n",
        "        classifier2 = self.classifier2(x)\n",
        "\n",
        "        return classifier1, classifier2\n",
        "\n",
        "# Instantiate the model\n",
        "model = MiniNet().to(\"cuda\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7OPY0qlCQMiz"
      },
      "source": [
        "## Defining Optimizer and loss for training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "3uHGAKHHZk8v"
      },
      "outputs": [],
      "source": [
        "from loss import TotalLoss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "ac7Fw1ksZoBh"
      },
      "outputs": [],
      "source": [
        "optimizer = torch.optim.Adam(model.parameters(), 5e-4, (0.9, 0.999), eps=1e-08, weight_decay=5e-4)\n",
        "criterion = TotalLoss()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EH08lQX4QVnY"
      },
      "source": [
        "## Defining Custom metrics for evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "_P6UMIX6hlef"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "class SegmentationMetric(object):\n",
        "    '''\n",
        "    imgLabel [batch_size, height(144), width(256)]\n",
        "    confusionMatrix [[0(TN),1(FP)],\n",
        "                     [2(FN),3(TP)]]\n",
        "    '''\n",
        "    def __init__(self, numClass):\n",
        "        self.numClass = numClass\n",
        "        self.confusionMatrix = np.zeros((self.numClass,)*2)\n",
        "\n",
        "    def pixelAccuracy(self):\n",
        "        # return all class overall pixel accuracy\n",
        "        # acc = (TP + TN) / (TP + TN + FP + TN)\n",
        "        acc = np.diag(self.confusionMatrix).sum() /  self.confusionMatrix.sum()\n",
        "        return acc\n",
        "\n",
        "\n",
        "    def classPixelAccuracy(self):\n",
        "        # return each category pixel accuracy(A more accurate way to call it precision)\n",
        "        # acc = (TP) / TP + FP\n",
        "        classAcc = np.diag(self.confusionMatrix) / (self.confusionMatrix.sum(axis=0) + 1e-12)\n",
        "        return classAcc\n",
        "\n",
        "    def meanPixelAccuracy(self):\n",
        "        classAcc = self.classPixelAccuracy()\n",
        "        meanAcc = np.nanmean(classAcc)\n",
        "        return meanAcc\n",
        "\n",
        "    def meanIntersectionOverUnion(self):\n",
        "        # Intersection = TP Union = TP + FP + FN\n",
        "        # IoU = TP / (TP + FP + FN)\n",
        "        intersection = np.diag(self.confusionMatrix)\n",
        "        union = np.sum(self.confusionMatrix, axis=1) + np.sum(self.confusionMatrix, axis=0) - np.diag(self.confusionMatrix)\n",
        "        IoU = intersection / union\n",
        "        IoU[np.isnan(IoU)] = 0\n",
        "        mIoU = np.nanmean(IoU)\n",
        "        return mIoU\n",
        "\n",
        "    def IntersectionOverUnion(self):\n",
        "        intersection = np.diag(self.confusionMatrix)\n",
        "        union = np.sum(self.confusionMatrix, axis=1) + np.sum(self.confusionMatrix, axis=0) - np.diag(self.confusionMatrix)\n",
        "        IoU = intersection / union\n",
        "        IoU[np.isnan(IoU)] = 0\n",
        "        return IoU[1]\n",
        "\n",
        "    def genConfusionMatrix(self, imgPredict, imgLabel):\n",
        "        # remove classes from unlabeled pixels in gt image and predict\n",
        "        # print(imgLabel.shape)\n",
        "        mask = (imgLabel >= 0) & (imgLabel < self.numClass)\n",
        "        label = self.numClass * imgLabel[mask] + imgPredict[mask]\n",
        "        count = np.bincount(label, minlength=self.numClass**2)\n",
        "        confusionMatrix = count.reshape(self.numClass, self.numClass)\n",
        "        return confusionMatrix\n",
        "\n",
        "    def Frequency_Weighted_Intersection_over_Union(self):\n",
        "        # FWIOU =     [(TP+FN)/(TP+FP+TN+FN)] *[TP / (TP + FP + FN)]\n",
        "        freq = np.sum(self.confusionMatrix, axis=1) / np.sum(self.confusionMatrix)\n",
        "        iu = np.diag(self.confusionMatrix) / (\n",
        "                np.sum(self.confusionMatrix, axis=1) + np.sum(self.confusionMatrix, axis=0) -\n",
        "                np.diag(self.confusionMatrix))\n",
        "        FWIoU = (freq[freq > 0] * iu[freq > 0]).sum()\n",
        "        return FWIoU\n",
        "\n",
        "\n",
        "    def addBatch(self, imgPredict, imgLabel):\n",
        "        assert imgPredict.shape == imgLabel.shape\n",
        "        self.confusionMatrix += self.genConfusionMatrix(imgPredict, imgLabel)\n",
        "\n",
        "    def reset(self):\n",
        "        self.confusionMatrix = np.zeros((self.numClass, self.numClass))\n",
        "\n",
        "class AverageMeter(object):\n",
        "    \"\"\"Computes and stores the average and current value\"\"\"\n",
        "    def __init__(self):\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.val = 0\n",
        "        self.avg = 0\n",
        "        self.sum = 0\n",
        "        self.count = 0\n",
        "\n",
        "    def update(self, val, n=1):\n",
        "        self.val = val\n",
        "        self.sum += val * n\n",
        "        self.count += n\n",
        "        self.avg = self.sum / self.count if self.count != 0 else 0\n",
        "\n",
        "@torch.no_grad()\n",
        "def val(val_loader, model):\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "\n",
        "    DA=SegmentationMetric(2)\n",
        "    LL=SegmentationMetric(2)\n",
        "\n",
        "    da_acc_seg = AverageMeter()\n",
        "    da_IoU_seg = AverageMeter()\n",
        "    da_mIoU_seg = AverageMeter()\n",
        "\n",
        "    ll_acc_seg = AverageMeter()\n",
        "    ll_IoU_seg = AverageMeter()\n",
        "    ll_mIoU_seg = AverageMeter()\n",
        "    total_batches = len(val_loader)\n",
        "\n",
        "    total_batches = len(val_loader)\n",
        "    pbar = enumerate(val_loader)\n",
        "    pbar = tqdm(pbar, total=total_batches)\n",
        "    for i, (_, _,input, target) in pbar:\n",
        "        input = input.cuda().float() / 255.0\n",
        "            # target = target.cuda()\n",
        "\n",
        "        input_var = input\n",
        "        target_var = target\n",
        "\n",
        "        # run the mdoel\n",
        "        with torch.no_grad():\n",
        "            output = model(input_var)\n",
        "\n",
        "        out_da,out_ll=output\n",
        "        target_da,target_ll=target\n",
        "\n",
        "        _,da_predict=torch.max(out_da, 1)\n",
        "        _,da_gt=torch.max(target_da, 1)\n",
        "\n",
        "        _,ll_predict=torch.max(out_ll, 1)\n",
        "        _,ll_gt=torch.max(target_ll, 1)\n",
        "        DA.reset()\n",
        "        DA.addBatch(da_predict.cpu(), da_gt.cpu())\n",
        "\n",
        "\n",
        "        da_acc = DA.pixelAccuracy()\n",
        "        da_IoU = DA.IntersectionOverUnion()\n",
        "        da_mIoU = DA.meanIntersectionOverUnion()\n",
        "\n",
        "        da_acc_seg.update(da_acc,input.size(0))\n",
        "        da_IoU_seg.update(da_IoU,input.size(0))\n",
        "        da_mIoU_seg.update(da_mIoU,input.size(0))\n",
        "\n",
        "\n",
        "        LL.reset()\n",
        "        LL.addBatch(ll_predict.cpu(), ll_gt.cpu())\n",
        "\n",
        "\n",
        "        ll_acc = LL.pixelAccuracy()\n",
        "        ll_IoU = LL.IntersectionOverUnion()\n",
        "        ll_mIoU = LL.meanIntersectionOverUnion()\n",
        "\n",
        "        ll_acc_seg.update(ll_acc,input.size(0))\n",
        "        ll_IoU_seg.update(ll_IoU,input.size(0))\n",
        "        ll_mIoU_seg.update(ll_mIoU,input.size(0))\n",
        "\n",
        "    da_segment_result = (da_acc_seg.avg,da_IoU_seg.avg,da_mIoU_seg.avg)\n",
        "    ll_segment_result = (ll_acc_seg.avg,ll_IoU_seg.avg,ll_mIoU_seg.avg)\n",
        "    return da_segment_result,ll_segment_result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hbkoWq9kQaWJ"
      },
      "source": [
        "## Training The model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "9tWePJj0Zvvo",
        "outputId": "a2773a4f-b34e-492c-8db9-e34227ccb0a6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss: 1.21158\n",
            "Accuracy:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:01<00:00,  1.36s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Driving area Segment: Acc(0.856)\n",
            "Lane line Segment: Acc(0.993)\n",
            "\n",
            "Validation Evaluation:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3/3 [00:03<00:00,  1.12s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Driving area Segment: Acc(0.798)    IOU (0.000)    mIOU(0.399)\n",
            "Lane line Segment: Acc(0.981)    IOU (0.000)  mIOU(0.491)\n",
            "----------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/jit/_trace.py:787: UserWarning: The input to trace is already a ScriptModule, tracing it is a no-op. Returning the object as is.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss: 0.91062\n",
            "Accuracy:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 11.03it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Driving area Segment: Acc(0.856)\n",
            "Lane line Segment: Acc(0.993)\n",
            "\n",
            "Validation Evaluation:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3/3 [00:01<00:00,  2.50it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Driving area Segment: Acc(0.798)    IOU (0.000)    mIOU(0.399)\n",
            "Lane line Segment: Acc(0.981)    IOU (0.000)  mIOU(0.491)\n",
            "----------------------------------------------------------------\n",
            "loss: 0.70817\n",
            "Accuracy:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  9.49it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Driving area Segment: Acc(0.858)\n",
            "Lane line Segment: Acc(0.993)\n",
            "\n",
            "Validation Evaluation:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3/3 [00:01<00:00,  2.50it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Driving area Segment: Acc(0.798)    IOU (0.000)    mIOU(0.399)\n",
            "Lane line Segment: Acc(0.981)    IOU (0.000)  mIOU(0.491)\n",
            "----------------------------------------------------------------\n",
            "loss: 0.51835\n",
            "Accuracy:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  9.17it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Driving area Segment: Acc(0.681)\n",
            "Lane line Segment: Acc(0.995)\n",
            "\n",
            "Validation Evaluation:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3/3 [00:01<00:00,  1.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Driving area Segment: Acc(0.868)    IOU (0.469)    mIOU(0.659)\n",
            "Lane line Segment: Acc(0.981)    IOU (0.000)  mIOU(0.491)\n",
            "----------------------------------------------------------------\n",
            "loss: 0.28514\n",
            "Accuracy:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  6.28it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Driving area Segment: Acc(0.753)\n",
            "Lane line Segment: Acc(0.996)\n",
            "\n",
            "Validation Evaluation:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3/3 [00:01<00:00,  2.51it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Driving area Segment: Acc(0.839)    IOU (0.414)    mIOU(0.616)\n",
            "Lane line Segment: Acc(0.975)    IOU (0.016)  mIOU(0.495)\n",
            "----------------------------------------------------------------\n",
            "loss: 0.12501\n",
            "Accuracy:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 10.71it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Driving area Segment: Acc(0.954)\n",
            "Lane line Segment: Acc(0.996)\n",
            "\n",
            "Validation Evaluation:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3/3 [00:01<00:00,  2.50it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Driving area Segment: Acc(0.848)    IOU (0.439)    mIOU(0.633)\n",
            "Lane line Segment: Acc(0.972)    IOU (0.018)  mIOU(0.495)\n",
            "----------------------------------------------------------------\n",
            "loss: 0.10251\n",
            "Accuracy:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 10.26it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Driving area Segment: Acc(0.901)\n",
            "Lane line Segment: Acc(0.994)\n",
            "\n",
            "Validation Evaluation:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3/3 [00:01<00:00,  2.43it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Driving area Segment: Acc(0.848)    IOU (0.440)    mIOU(0.633)\n",
            "Lane line Segment: Acc(0.970)    IOU (0.018)  mIOU(0.494)\n",
            "----------------------------------------------------------------\n",
            "loss: 0.08780\n",
            "Accuracy:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 10.35it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Driving area Segment: Acc(0.862)\n",
            "Lane line Segment: Acc(0.996)\n",
            "\n",
            "Validation Evaluation:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3/3 [00:01<00:00,  2.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Driving area Segment: Acc(0.846)    IOU (0.431)    mIOU(0.629)\n",
            "Lane line Segment: Acc(0.968)    IOU (0.016)  mIOU(0.492)\n",
            "----------------------------------------------------------------\n",
            "loss: 0.07377\n",
            "Accuracy:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  6.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Driving area Segment: Acc(0.970)\n",
            "Lane line Segment: Acc(0.996)\n",
            "\n",
            "Validation Evaluation:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Driving area Segment: Acc(0.846)    IOU (0.414)    mIOU(0.621)\n",
            "Lane line Segment: Acc(0.963)    IOU (0.013)  mIOU(0.488)\n",
            "----------------------------------------------------------------\n",
            "loss: 0.06286\n",
            "Accuracy:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  6.28it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Driving area Segment: Acc(0.955)\n",
            "Lane line Segment: Acc(0.998)\n",
            "\n",
            "Validation Evaluation:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Driving area Segment: Acc(0.849)    IOU (0.396)    mIOU(0.614)\n",
            "Lane line Segment: Acc(0.961)    IOU (0.018)  mIOU(0.490)\n",
            "----------------------------------------------------------------\n",
            "loss: 0.05484\n",
            "Accuracy:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 10.62it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Driving area Segment: Acc(0.973)\n",
            "Lane line Segment: Acc(0.997)\n",
            "\n",
            "Validation Evaluation:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3/3 [00:01<00:00,  2.49it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Driving area Segment: Acc(0.855)    IOU (0.390)    mIOU(0.615)\n",
            "Lane line Segment: Acc(0.959)    IOU (0.017)  mIOU(0.488)\n",
            "----------------------------------------------------------------\n",
            "loss: 0.04588\n",
            "Accuracy:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  3.45it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Driving area Segment: Acc(0.913)\n",
            "Lane line Segment: Acc(0.995)\n",
            "\n",
            "Validation Evaluation:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3/3 [00:02<00:00,  1.25it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Driving area Segment: Acc(0.848)    IOU (0.357)    mIOU(0.596)\n",
            "Lane line Segment: Acc(0.961)    IOU (0.016)  mIOU(0.488)\n",
            "----------------------------------------------------------------\n",
            "loss: 0.03685\n",
            "Accuracy:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  5.11it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Driving area Segment: Acc(0.955)\n",
            "Lane line Segment: Acc(0.996)\n",
            "\n",
            "Validation Evaluation:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3/3 [00:01<00:00,  2.33it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Driving area Segment: Acc(0.855)    IOU (0.368)    mIOU(0.605)\n",
            "Lane line Segment: Acc(0.956)    IOU (0.020)  mIOU(0.488)\n",
            "----------------------------------------------------------------\n",
            "loss: 0.03707\n",
            "Accuracy:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  9.27it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Driving area Segment: Acc(0.944)\n",
            "Lane line Segment: Acc(0.996)\n",
            "\n",
            "Validation Evaluation:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3/3 [00:01<00:00,  2.41it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Driving area Segment: Acc(0.860)    IOU (0.407)    mIOU(0.626)\n",
            "Lane line Segment: Acc(0.952)    IOU (0.016)  mIOU(0.484)\n",
            "----------------------------------------------------------------\n",
            "loss: 0.03035\n",
            "Accuracy:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 10.26it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Driving area Segment: Acc(0.960)\n",
            "Lane line Segment: Acc(0.998)\n",
            "\n",
            "Validation Evaluation:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3/3 [00:01<00:00,  2.46it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Driving area Segment: Acc(0.849)    IOU (0.342)    mIOU(0.589)\n",
            "Lane line Segment: Acc(0.957)    IOU (0.018)  mIOU(0.488)\n",
            "----------------------------------------------------------------\n",
            "loss: 0.02830\n",
            "Accuracy:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 10.40it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Driving area Segment: Acc(0.942)\n",
            "Lane line Segment: Acc(0.997)\n",
            "\n",
            "Validation Evaluation:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3/3 [00:01<00:00,  2.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Driving area Segment: Acc(0.850)    IOU (0.354)    mIOU(0.595)\n",
            "Lane line Segment: Acc(0.957)    IOU (0.018)  mIOU(0.487)\n",
            "----------------------------------------------------------------\n",
            "loss: 0.02667\n",
            "Accuracy:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  6.09it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Driving area Segment: Acc(0.949)\n",
            "Lane line Segment: Acc(0.987)\n",
            "\n",
            "Validation Evaluation:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Driving area Segment: Acc(0.850)    IOU (0.343)    mIOU(0.590)\n",
            "Lane line Segment: Acc(0.957)    IOU (0.020)  mIOU(0.488)\n",
            "----------------------------------------------------------------\n",
            "loss: 0.02541\n",
            "Accuracy:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 11.25it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Driving area Segment: Acc(0.955)\n",
            "Lane line Segment: Acc(0.998)\n",
            "\n",
            "Validation Evaluation:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3/3 [00:01<00:00,  2.63it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Driving area Segment: Acc(0.849)    IOU (0.321)    mIOU(0.578)\n",
            "Lane line Segment: Acc(0.958)    IOU (0.021)  mIOU(0.490)\n",
            "----------------------------------------------------------------\n",
            "loss: 0.02420\n",
            "Accuracy:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  9.43it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Driving area Segment: Acc(0.953)\n",
            "Lane line Segment: Acc(0.997)\n",
            "\n",
            "Validation Evaluation:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3/3 [00:01<00:00,  2.62it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Driving area Segment: Acc(0.848)    IOU (0.336)    mIOU(0.586)\n",
            "Lane line Segment: Acc(0.961)    IOU (0.021)  mIOU(0.491)\n",
            "----------------------------------------------------------------\n",
            "loss: 0.02297\n",
            "Accuracy:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  8.45it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Driving area Segment: Acc(0.988)\n",
            "Lane line Segment: Acc(0.998)\n",
            "\n",
            "Validation Evaluation:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3/3 [00:01<00:00,  2.61it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Driving area Segment: Acc(0.851)    IOU (0.354)    mIOU(0.596)\n",
            "Lane line Segment: Acc(0.958)    IOU (0.020)  mIOU(0.489)\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "val_loss = []\n",
        "train_loss = []\n",
        "\n",
        "for i in list(range(1000)):\n",
        "    model.train()\n",
        "    model.to(\"cuda\")\n",
        "    output = model(input.cuda().float() / 255.0)\n",
        "\n",
        "    # target=target.cuda()\n",
        "    # print(target[0].size())\n",
        "    optimizer.zero_grad()\n",
        "    focal_loss, tversky_loss, loss = criterion(output,target)\n",
        "    optimizer.zero_grad()\n",
        "    train_loss.append(loss.item())\n",
        "    # print(output.size())\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    if i % 50 == 0:\n",
        "        print(\"loss: {loss:.5f}\".format(loss = loss.item()))\n",
        "        model.eval()\n",
        "        example = torch.rand(1, 3, 360, 640).cuda()\n",
        "        model = torch.jit.trace(model, example)\n",
        "        print(\"Accuracy:\")\n",
        "        da_segment_results,ll_segment_results = val(train_dataloader, model)\n",
        "\n",
        "        msg =  'Driving area Segment: Acc({da_seg_acc:.3f})\\n' \\\n",
        "                            'Lane line Segment: Acc({ll_seg_acc:.3f})'.format(\n",
        "                                da_seg_acc=da_segment_results[0],\n",
        "                                ll_seg_acc=ll_segment_results[0])\n",
        "        print(msg)\n",
        "        print()\n",
        "        print(\"Validation Evaluation:\")\n",
        "        da_segment_results,ll_segment_results = val(val_dataloader, model)\n",
        "\n",
        "        msg =  'Driving area Segment: Acc({da_seg_acc:.3f})    IOU ({da_seg_iou:.3f})    mIOU({da_seg_miou:.3f})\\n' \\\n",
        "                            'Lane line Segment: Acc({ll_seg_acc:.3f})    IOU ({ll_seg_iou:.3f})  mIOU({ll_seg_miou:.3f})'.format(\n",
        "                                da_seg_acc=da_segment_results[0],da_seg_iou=da_segment_results[1],da_seg_miou=da_segment_results[2],\n",
        "                                ll_seg_acc=ll_segment_results[0],ll_seg_iou=ll_segment_results[1],ll_seg_miou=ll_segment_results[2])\n",
        "        print(msg)\n",
        "        print(\"----------------------------------------------------------------\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jmb_9DeFQdLk"
      },
      "source": [
        "## Evaluating the model on the test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "GcNA2z01LJgP",
        "outputId": "ec324738-ab1c-44b4-9cc3-e71a4074b49d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Evaluation:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3/3 [00:01<00:00,  2.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Driving area Segment: Acc(0.834)    IOU (0.226)    mIOU(0.526)\n",
            "Lane line Segment: Acc(0.976)    IOU (0.024)  mIOU(0.500)\n",
            "----------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "print(\"Test Evaluation:\")\n",
        "da_segment_results,ll_segment_results = val(test_dataloader, model)\n",
        "\n",
        "msg =  '\\nDriving area Segment: Acc({da_seg_acc:.3f})    IOU ({da_seg_iou:.3f})    mIOU({da_seg_miou:.3f})\\n' \\\n",
        "                    'Lane line Segment: Acc({ll_seg_acc:.3f})    IOU ({ll_seg_iou:.3f})  mIOU({ll_seg_miou:.3f})'.format(\n",
        "                        da_seg_acc=da_segment_results[0],da_seg_iou=da_segment_results[1],da_seg_miou=da_segment_results[2],\n",
        "                        ll_seg_acc=ll_segment_results[0],ll_seg_iou=ll_segment_results[1],ll_seg_miou=ll_segment_results[2])\n",
        "print(msg)\n",
        "print(\"----------------------------------------------------------------\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FJ26XV4lrQPl"
      },
      "execution_count": 18,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}